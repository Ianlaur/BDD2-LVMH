# LVMH Voice-to-Tag â€” Vector Profiles

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.14+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/NLP-Hybrid-green.svg" alt="NLP">
  <img src="https://img.shields.io/badge/Languages-12+-orange.svg" alt="Languages">
  <img src="https://img.shields.io/badge/LLM-Qwen2.5-purple.svg" alt="Qwen LLM">
  <img src="https://img.shields.io/badge/Vocabulary-575%20concepts-teal.svg" alt="Vocabulary">
  <img src="https://img.shields.io/badge/Concepts-1796%20detected-success.svg" alt="Detected">
</p>

Pipeline **hybride (Rule-based + LLM)** et multilingue qui transforme les transcriptions des Conseillers de Vente en profils clients actionnables et recommandations personnalisÃ©es.

**âœ¨ Nouveau (Production v1.0):** 
- **Qwen LLM Enhancement**: Extraction sÃ©mantique avec Qwen2.5:3b (342 concepts supplÃ©mentaires)
- **Budget Detection**: Extraction regex des montants (100% coverage)
- **Per-Client Tags**: 12 tags personnalisÃ©s par client (budget en premier)
- **Big O Performance**: Tests de complexitÃ© validÃ©s (11/11 passing)
- **Anonymisation RGPD/GDPR automatique** ğŸ”’

---

## ğŸ¯ Objectifs

Transformer automatiquement les notes vocales des conseillers en :
- **Tags structurÃ©s** (prÃ©fÃ©rences, occasions, contraintes, budgets)
- **Profils clients** segmentÃ©s par similaritÃ© (12 tags personnalisÃ©s par client)
- **Actions recommandÃ©es** personnalisÃ©es
- **Visualisation 3D** interactive de l'espace client
- **Extraction sÃ©mantique** via Qwen LLM (au-delÃ  des rÃ¨gles)

### ğŸ§  Approche Hybride

Le systÃ¨me combine trois mÃ©thodes complÃ©mentaires:

1. **Rule-Based Matching** (Aho-Corasick) â€” 1,454 concepts
   - Correspondance rapide d'alias multilingues
   - DÃ©terministe et explicable
   - ComplexitÃ© O(N+M) â€” linÃ©aire

2. **Regex Patterns** â€” Extraction de budgets
   - Montants, ranges, devises
   - 100% coverage sur notes avec budget
   - Pattern: `budget/price 3-4k`, `â‚¬1500`, `25K+`

3. **Qwen LLM Enhancement** (Qwen2.5:3b) â€” 342 concepts supplÃ©mentaires
   - Extraction sÃ©mantique des concepts que les rÃ¨gles manquent
   - OptimisÃ©: ~10s/note, 99% success rate
   - Filtres qualitÃ©: anti-hallucination, snake_case, duplicates
   - Confidence moyenne: 0.91

**Total: 1,796 concepts dÃ©tectÃ©s** (1,454 rule-based + 342 LLM)

## ğŸ”’ ConformitÃ© RGPD/GDPR

Le pipeline inclut un **module d'anonymisation automatique** qui dÃ©tecte et supprime les informations personnelles sensibles :
- Noms, emails, tÃ©lÃ©phones
- Adresses postales
- Cartes bancaires, IBAN
- NumÃ©ros d'identitÃ©
- Dates de naissance

Les insights mÃ©tier (prÃ©fÃ©rences produits, intentions, contextes) sont **prÃ©servÃ©s** pour l'analyse.

ğŸ“– **Documentation complÃ¨te:** [docs/ANONYMIZATION.md](docs/ANONYMIZATION.md)

```bash
# Activer/dÃ©sactiver l'anonymisation (activÃ©e par dÃ©faut)
ENABLE_ANONYMIZATION=true python -m server.run_all

# Mode agressif (dÃ©tecte plus de noms, plus de faux positifs)
ANONYMIZATION_AGGRESSIVE=true python -m server.run_all
```

---

## ğŸš€ DÃ©marrage Rapide

### Option 1: ExÃ©cutable (RecommandÃ©)

**macOS:**
```bash
# Double-cliquez sur le fichier ou exÃ©cutez:
./LVMH_Pipeline.command
```

**Windows:**
```cmd
# Double-cliquez sur le fichier ou exÃ©cutez:
LVMH_Pipeline.bat
```

### Option 2: Ligne de commande

```bash
# 1. CrÃ©er l'environnement virtuel
make venv

# 2. TÃ©lÃ©charger le modÃ¨le d'embedding
make setup-models-local

# 3. Placer votre CSV dans data/raw/

# 4. Lancer le pipeline
make dev
```

### Option 3: Docker (ReproductibilitÃ© garantie)

```bash
# Construire et lancer
make build && make run
```

---

## ğŸ§  EntraÃ®nement du Vocabulaire

Le pipeline utilise un vocabulaire entraÃ®nable de **575 concepts** avec **9,003 aliases** multilingues (12+ langues).

### Statistiques Actuelles (Production v1.0)

| Bucket | Concepts | Exemples | LLM Boost |
|--------|----------|----------|-----------|
| **preferences** | 167 | marques, matÃ©riaux, styles | +34% detection |
| **intent** | 71 | Ã©motions, intentions d'achat | +28% detection |
| **lifestyle** | 71 | famille, personnalitÃ©, VIP | +31% detection |
| **occasion** | 36 | fÃªtes, Ã©vÃ©nements, Ã©tapes | +25% detection |
| **constraints** | 20 | **budget**, dÃ©lais, canaux | **100% coverage** |
| **next_action** | 19 | rendez-vous, rÃ©paration | +22% detection |

### Extraction de Budgets

Le systÃ¨me dÃ©tecte automatiquement les montants budgÃ©taires via regex:

```python
# Patterns dÃ©tectÃ©s:
"budget 3-4k"           â†’ BUDGET_AMOUNT: budget 3-4k
"presupuesto 25-30k"    â†’ BUDGET_AMOUNT: budget 25-30k  
"prix 1500â‚¬"            â†’ BUDGET_AMOUNT: budget 1500â‚¬
"price around 40K+"     â†’ BUDGET_AMOUNT: budget 40k+
```

**Coverage: 100/100 notes** | Range: â‚¬1,500 - â‚¬40,000+ | Moyenne: â‚¬13,070

### Commandes CLI

```bash
# Voir les statistiques du vocabulaire
python -m server.server.train_vocabulary stats

# Ajouter un mot-clÃ© manuellement
python -m server.server.train_vocabulary add "terme" "Label FR" "bucket" --aliases "alias1,alias2,åˆ«å"

# Importer des mots-clÃ©s depuis un fichier JSON
python -m server.server.train_vocabulary import taxonomy/training_keywords.json

# Charger les mots-clÃ©s prÃ©dÃ©finis
python -m server.server.train_vocabulary load-predefined

# Lister les concepts d'un bucket
python -m server.server.train_vocabulary list --bucket preferences
```

### Format JSON pour Import

```json
[
  {
    "term": "hermÃ¨s",
    "label": "HermÃ¨s",
    "bucket": "preferences",
    "aliases": ["hermes", "ã‚¨ãƒ«ãƒ¡ã‚¹", "çˆ±é©¬ä»•", "ì—ë¥´ë©”ìŠ¤"]
  },
  {
    "term": "anniversary",
    "label": "Anniversaire",
    "bucket": "occasion",
    "aliases": ["anniversaire", "compleanno", "cumpleaÃ±os", "è¨˜å¿µæ—¥", "ê¸°ë…ì¼"]
  }
]
```

### Langues SupportÃ©es dans le Vocabulaire

| Code | Langue | Code | Langue |
|------|--------|------|--------|
| EN | English | ZH | ä¸­æ–‡ |
| FR | FranÃ§ais | JA | æ—¥æœ¬èª |
| IT | Italiano | KO | í•œêµ­ì–´ |
| ES | EspaÃ±ol | RU | Ğ ÑƒÑÑĞºĞ¸Ğ¹ |
| DE | Deutsch | AR | Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© |
| PT | PortuguÃªs | NL | Nederlands |

---

## ğŸ“Š Architecture du Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LVMH Voice-to-Tag Pipeline (Hybrid v1.0)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  STAGE 1 â”‚â”€â”€â”€â–¶â”‚  STAGE 2 â”‚â”€â”€â”€â–¶â”‚  STAGE 3 â”‚â”€â”€â”€â–¶â”‚  STAGE 4 â”‚              â”‚
â”‚  â”‚  Ingest  â”‚    â”‚ Extract  â”‚    â”‚  Lexicon â”‚    â”‚ Concepts â”‚              â”‚
â”‚  â”‚          â”‚    â”‚          â”‚    â”‚          â”‚    â”‚          â”‚              â”‚
â”‚  â”‚ CSV â”€â”€â–¶  â”‚    â”‚Rule-Basedâ”‚    â”‚ Embeddingâ”‚    â”‚ Aho-     â”‚              â”‚
â”‚  â”‚ Parquet  â”‚    â”‚  + LLM   â”‚    â”‚Clusteringâ”‚    â”‚Corasick  â”‚              â”‚
â”‚  â”‚          â”‚    â”‚  Qwen2.5 â”‚    â”‚          â”‚    â”‚+ Regex   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚       â”‚               â”‚               â”‚               â”‚                     â”‚
â”‚       â–¼               â–¼               â–¼               â–¼                     â”‚
â”‚  notes_clean     qwen_enhanced   lexicon_v1.csv  note_concepts             â”‚
â”‚   .parquet      _concepts.csv   taxonomy_v1.json   .csv                    â”‚
â”‚                  (342 LLM)        (575 concepts)  (1,796 total)            â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  STAGE 5 â”‚â”€â”€â”€â–¶â”‚  STAGE 6 â”‚â”€â”€â”€â–¶â”‚  STAGE 7 â”‚â”€â”€â”€â–¶â”‚  STAGE 8 â”‚              â”‚
â”‚  â”‚ Vectors  â”‚    â”‚ Profiles â”‚    â”‚ Actions  â”‚    â”‚Predictionsâ”‚             â”‚
â”‚  â”‚          â”‚    â”‚          â”‚    â”‚          â”‚    â”‚          â”‚              â”‚
â”‚  â”‚ Sentence â”‚    â”‚  KMeans  â”‚    â”‚ Playbook â”‚    â”‚ Purchase â”‚              â”‚
â”‚  â”‚Transformerâ”‚   â”‚ Per-Clientâ”‚   â”‚ Matching â”‚    â”‚Churn/CLV â”‚              â”‚
â”‚  â”‚          â”‚    â”‚  12 Tags â”‚    â”‚          â”‚    â”‚          â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚       â”‚               â”‚               â”‚               â”‚                     â”‚
â”‚       â–¼               â–¼               â–¼               â–¼                     â”‚
â”‚  note_vectors    client_profiles  recommended    ml_predictions            â”‚
â”‚   .parquet          .csv         _actions.csv       .csv                   â”‚
â”‚                  (budget 1st)                                               â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚  STAGE 9 â”‚â”€â”€â”€â–¶â”‚ STAGE 10 â”‚                                               â”‚
â”‚  â”‚   K.G.   â”‚    â”‚Dashboard â”‚                                               â”‚
â”‚  â”‚          â”‚    â”‚          â”‚                                               â”‚
â”‚  â”‚ Neo4j /  â”‚    â”‚ React UI â”‚                                               â”‚
â”‚  â”‚ Cytoscapeâ”‚    â”‚ + API    â”‚                                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚       â”‚               â”‚                                                     â”‚
â”‚       â–¼               â–¼                                                     â”‚
â”‚  knowledge_graph  dashboard/                                                â”‚
â”‚     .json        src/data.json                                              â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”¬ Extraction Methods Comparison

| Method | Concepts | Speed | Precision | Coverage |
|--------|----------|-------|-----------|----------|
| **Aho-Corasick** | 1,454 | âš¡ <1ms/note | âœ… 100% | âš ï¸ 75% (missed semantic) |
| **Regex (Budget)** | 100 | âš¡ <1ms/note | âœ… 100% | âœ… 100% (budget notes) |
| **Qwen LLM** | 342 | ğŸ¢ ~10s/note | âš ï¸ 91% | âœ… 99% (semantic gaps) |
| **Combined** | **1,796** | âš¡ ~10s/note | âœ… 96% | âœ… 100% |

---

## ğŸ“ Structure des Fichiers

```
BDD2-LVMH/
â”œâ”€â”€ ğŸ“„ LVMH_Pipeline.command    # Lanceur macOS (double-clic)
â”œâ”€â”€ ğŸ“„ LVMH_Pipeline.bat        # Lanceur Windows (double-clic)
â”œâ”€â”€ ğŸ“„ makefile                 # Commandes make
â”œâ”€â”€ ğŸ“„ requirements.txt         # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ Dockerfile               # Container Docker
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md          # Documentation architecture
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ ğŸ“‚ input/               # â† Placez votre CSV ici
â”‚   â”œâ”€â”€ ğŸ“‚ processed/           # DonnÃ©es intermÃ©diaires
â”‚   â””â”€â”€ ğŸ“‚ outputs/             # RÃ©sultats finaux
â”‚
â”œâ”€â”€ ğŸ“‚ taxonomy/                # Lexique et vocabulaire entraÃ®nÃ©
â”‚   â”œâ”€â”€ vocabulary.json         # Vocabulaire (384 concepts)
â”‚   â”œâ”€â”€ lexicon_v1.json         # Lexique synchronisÃ©
â”‚   â””â”€â”€ taxonomy_v1.json        # Taxonomie par catÃ©gories
â”‚
â”œâ”€â”€ ğŸ“‚ activations/             # Playbooks d'actions (YAML)
â”œâ”€â”€ ğŸ“‚ models/                  # ModÃ¨le SentenceTransformer
â”‚
â”œâ”€â”€ ğŸ“‚ server/                  # ğŸ”§ Backend - Traitement de donnÃ©es
â”‚   â”œâ”€â”€ run_all.py              # Orchestrateur principal (10 stages)
â”‚   â”œâ”€â”€ api_server.py           # FastAPI REST API (port 8000)
â”‚   â”œâ”€â”€ ğŸ“‚ shared/              # Config & utilitaires
â”‚   â”‚   â”œâ”€â”€ config.py           # Configuration centrale
â”‚   â”‚   â”œâ”€â”€ utils.py            # Fonctions helper
â”‚   â”‚   â”œâ”€â”€ knowledge_graph.py  # Construction du graphe
â”‚   â”‚   â””â”€â”€ generate_dashboard.py # GÃ©nÃ©ration dashboard
â”‚   â”œâ”€â”€ ğŸ“‚ ingest/              # Ã‰tape 1: Ingestion CSV
â”‚   â”œâ”€â”€ ğŸ“‚ extract/             # Ã‰tapes 2-4: Extraction concepts
â”‚   â”‚   â”œâ”€â”€ detect_concepts.py  # Rule-based (Aho-Corasick + Regex)
â”‚   â”‚   â””â”€â”€ qwen_enhance.py     # LLM enhancement (Qwen2.5:3b)
â”‚   â”œâ”€â”€ ğŸ“‚ lexicon/             # Ã‰tape 3: Construction lexique
â”‚   â”œâ”€â”€ ğŸ“‚ embeddings/          # Ã‰tapes 5 & 8: Vecteurs & UMAP 3D
â”‚   â”œâ”€â”€ ğŸ“‚ profiling/           # Ã‰tape 6: Segmentation clients
â”‚   â”‚   â””â”€â”€ segment_clients.py  # KMeans + per-client tags (12 tags)
â”‚   â”œâ”€â”€ ğŸ“‚ actions/             # Ã‰tape 7: Recommandations
â”‚   â”œâ”€â”€ ğŸ“‚ analytics/           # Ã‰tape 8: ML predictions
â”‚   â”œâ”€â”€ ğŸ“‚ db/                  # Database (Neon PostgreSQL)
â”‚   â”‚   â”œâ”€â”€ crud.py             # CRUD operations
â”‚   â”‚   â””â”€â”€ sync.py             # DB sync (100 clients)
â”‚   â””â”€â”€ ğŸ“‚ adaptive/            # Pipeline adaptatif
â”‚
â”œâ”€â”€ ğŸ“‚ client/                  # ğŸ¨ Frontend - Interface utilisateur
â”‚   â””â”€â”€ ğŸ“‚ app/                 # Application dashboard
â”‚       â”œâ”€â”€ dashboard.html      # Dashboard unifiÃ© (KG + 3D)
â”‚       â”œâ”€â”€ kg_obsidian.html    # Graphe de connaissance
â”‚       â”œâ”€â”€ embedding_space_3d.html # Espace vectoriel 3D
â”‚       â””â”€â”€ cytoscape.min.js    # BibliothÃ¨que visualisation
â”‚
â””â”€â”€ ğŸ“‚ docs/                    # Documentation
```

---

## ğŸ“¥ Format d'EntrÃ©e

### Mode Standard (Format LVMH)

Fichier CSV avec les colonnes suivantes:

| Colonne | Type | Description | Exemple |
|---------|------|-------------|---------|
| `ID` | string | Identifiant unique | `CA_001` |
| `Date` | string | Date d'interaction | `2024-01-15` |
| `Duration` | string | DurÃ©e | `35 min` |
| `Language` | string | Langue (FR/EN/IT/ES/DE) | `FR` |
| `Length` | string | Longueur | `medium` |
| `Transcription` | string | Contenu textuel | `Mme Dupont...` |

### Mode Adaptatif (N'importe quel CSV)

Le pipeline peut analyser automatiquement n'importe quel fichier CSV:

```bash
# Analyser la structure d'un CSV
python -m server.run_all --csv data/input/my_data.csv --analyze-only

# Lancer avec dÃ©tection automatique des colonnes
python -m server.run_all --csv data/input/my_data.csv

# SpÃ©cifier les colonnes manuellement
python -m server.run_all --csv data/input/my_data.csv --text-column "description" --id-column "client_id"
```

Le systÃ¨me dÃ©tecte automatiquement:
- **Colonne texte**: Plus longue moyenne de caractÃ¨res
- **Colonne ID**: Noms comme `id`, `client_id`, `code`
- **Colonne langue**: Noms comme `lang`, `language`, `langue`
- **Colonne date**: Formats date dÃ©tectÃ©s automatiquement

---

## ğŸ“¤ Fichiers de Sortie

### DonnÃ©es TraitÃ©es

| Fichier | Description |
|---------|-------------|
| `notes_clean.parquet` | Notes nettoyÃ©es et normalisÃ©es (100 notes) |
| `note_concepts_rules_only.csv` | Concepts rule-based uniquement (1,454) |
| `note_concepts_enhanced.csv` | Concepts rule-based + LLM (1,796) |
| `qwen_checkpoints/*.json` | Checkpoints Qwen par note (resume capability) |

### Taxonomie

| Fichier | Description |
|---------|-------------|
| `vocabulary.json` | **Vocabulaire entraÃ®nÃ©** (575 concepts, 9,003 aliases) |
| `lexicon_v1.json` | Lexique synchronisÃ© avec alias et frÃ©quences |
| `lexicon_v1.csv` | Version CSV du lexique |
| `taxonomy_v1.json` | Taxonomie par catÃ©gories (6 buckets) |

### RÃ©sultats

| Fichier | Description |
|---------|-------------|
| `note_concepts.csv` | **1,796 concepts** (1,454 rule + 342 LLM) avec positions |
| `note_vectors.parquet` | Embeddings 384 dimensions par note |
| `client_profiles.csv` | Segments clients avec **12 tags personnalisÃ©s** (budget 1st) |
| `client_summaries.json` | 99 rÃ©sumÃ©s LLM avec urgency/sentiment |
| `recommended_actions.csv` | Actions recommandÃ©es par client |
| `ml_predictions.csv` | Purchase probability, churn risk, CLV |
| `embedding_space_3d.html` | Visualisation 3D interactive |

---

## ğŸ”§ Technologies UtilisÃ©es

### Extraction Hybride (Rule-Based + LLM)

**Rule-Based (DÃ©terministe)**:
- **Aho-Corasick** - Correspondance multi-pattern O(N+M)
- **Regex** - Extraction de budgets (montants, ranges, devises)
- **TF-IDF** - Term Frequency-Inverse Document Frequency

**LLM Enhancement (SÃ©mantique)**:
- **Qwen2.5:3b** via Ollama - 1.9GB, 3.1B params
  - Context: 2048 tokens
  - Output: 512 tokens  
  - Timeout: 45s Ã— 2 retries
  - Format: JSON strict
  - Performance: ~10s/note, 99% success
  - Confidence: 0.91 avg

### Embeddings & Clustering
- **SentenceTransformers** - `paraphrase-multilingual-MiniLM-L12-v2`
  - Support multilingue (50+ langues)
  - 384 dimensions
  - OptimisÃ© pour similaritÃ© sÃ©mantique
- **KMeans** - Segmentation clients (7 clusters)
- **Silhouette Score** - Validation clustering (0.0573)

### Machine Learning
- **scikit-learn** - RandomForestClassifier, GradientBoostingRegressor
  - Purchase probability prediction
  - Churn risk prediction
  - Customer Lifetime Value (CLV) estimation

### Database & API
- **Neon PostgreSQL** - Cloud-hosted database
  - 100 clients synced
  - 1,919 concept extractions
  - Per-client tags (budget first)
- **FastAPI** - REST API server (port 8000)
  - `/api/clients` - List clients
  - `/api/clients/{id}` - Client 360Â° view
  - `/api/predictions` - ML predictions
  - `/api/dashboard` - Dashboard data

### Visualisation
- **UMAP** - RÃ©duction dimensionnelle non-linÃ©aire
- **Plotly** - Graphiques 3D interactifs
- **React/TypeScript** - Dashboard frontend (Vite)

### Performance Testing
- **pytest** - Unit testing framework
- **Big O Complexity Tests** - 11 tests validating scalability
  - All passing in 5.15s
  - Linear algorithms: O(N) with b < 1.6
  - Quadratic operations: O(NÂ²) with b < 2.8

### DÃ©terminisme
- Seeds fixes: `RANDOM_SEED=42`, `NUMPY_SEED=42`
- ReproductibilitÃ© garantie (hors LLM)

---

## âš™ï¸ Configuration

Fichier `server/shared/config.py`:

```python
# Seeds pour reproductibilitÃ©
RANDOM_SEED = 42
NUMPY_SEED = 42
SKLEARN_RANDOM_STATE = 42
UMAP_RANDOM_STATE = 42

# ModÃ¨le d'embedding
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

# Clustering
N_CLUSTERS = 7                      # Segments clients (KMeans)
SILHOUETTE_THRESHOLD = 0.0          # Validation clustering

# Extraction
MIN_CANDIDATE_FREQ = 2              # FrÃ©quence minimale

# LLM Enhancement (Qwen2.5:3b)
QWEN_MODEL = "qwen2.5:3b"
QWEN_TIMEOUT = 45                   # seconds per retry
QWEN_RETRIES = 2
QWEN_NUM_CTX = 2048                 # context window
QWEN_NUM_PREDICT = 512              # max output tokens
QWEN_TEMPERATURE = 0.15             # low for consistency
QWEN_REPEAT_PENALTY = 1.3           # avoid repetition
```

### Variables d'Environnement (.env)

```bash
# Database
DATABASE_URL=postgresql://user:pass@host/db

# Ollama
OLLAMA_BASE_URL=http://localhost:11434

# Anonymization (GDPR)
ENABLE_ANONYMIZATION=true
ANONYMIZATION_AGGRESSIVE=false

# Features
ENABLE_QWEN_ENHANCEMENT=true        # LLM semantic extraction
ENABLE_BUDGET_EXTRACTION=true       # Regex budget detection
```

---

## ğŸ¨ Visualisation 3D

La visualisation interactive (`demo/embedding_space_3d.html`) offre:

- **Carte de similaritÃ©**: Clients proches = profils similaires
- **Couleurs par segment**: 7 segments distincts avec lÃ©gende
- **Hover dÃ©taillÃ©**: Client ID, profil complet, note ID
- **Filtrage**: Cliquez sur la lÃ©gende pour afficher/masquer des segments
- **Rotation 3D**: Explorez l'espace client sous tous les angles

### Axes SÃ©mantiques
| Axe | Signification |
|-----|---------------|
| **X** | â† Classique \| Moderne â†’ |
| **Y** | â† Quotidien \| Ã‰vÃ©nements â†’ |
| **Z** | â† Budget \| Premium â†’ |

---

## ğŸ“‹ Playbooks d'Actions

Les recommandations sont basÃ©es sur 10 playbooks configurables (`activations/playbooks.yml`):

| Action | DÃ©clencheurs |
|--------|--------------|
| VIP Event Invitation | client_vip, events |
| New Collection Preview | style, fashion |
| Gift Occasion Follow-up | cadeau, anniversaire |
| Follow-up Appointment | rappeler, next_action |
| Budget-Sensitive Presentation | budget |
| Family Package Offer | famille, enfants |
| Travel Collection | voyage, travel |
| Anniversary Special | anniversaire, mariage |
| Dietary Accommodation | allergie, vÃ©gÃ©tarien, vÃ©gan |
| Personalized Recommendation | lifestyle, preferences |

---

## ğŸŒ Langues SupportÃ©es

### Traitement des Transcriptions

| Code | Langue | Exemple de Transcription |
|------|--------|--------------------------|
| FR | FranÃ§ais | "Mme Dupont cherche un cadeau pour son mari" |
| EN | English | "Mrs. Anderson is looking for elegant pieces" |
| IT | Italiano | "Signora Rossi cerca regali per la famiglia" |
| ES | EspaÃ±ol | "Sra. GarcÃ­a busca artÃ­culos de lujo" |
| DE | Deutsch | "Frau Schmidt sucht Geschenke fÃ¼r ihren Mann" |

### Vocabulaire Multilingue (12+ langues)

Le vocabulaire entraÃ®nÃ© supporte des alias dans:
- ğŸ‡¬ğŸ‡§ English, ğŸ‡«ğŸ‡· FranÃ§ais, ğŸ‡®ğŸ‡¹ Italiano, ğŸ‡ªğŸ‡¸ EspaÃ±ol, ğŸ‡©ğŸ‡ª Deutsch
- ğŸ‡µğŸ‡¹ PortuguÃªs, ğŸ‡³ğŸ‡± Nederlands, ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹, ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
- ğŸ‡¨ğŸ‡³ ä¸­æ–‡, ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª, ğŸ‡°ğŸ‡· í•œêµ­ì–´

> **Note**: Les sorties sont **standardisÃ©es en franÃ§ais** pour cohÃ©rence.

---

## ğŸ³ Docker

### Construction
```bash
docker build -t lvmh-pipeline .
```

### ExÃ©cution
```bash
docker run -v $(pwd)/data:/app/data -v $(pwd)/taxonomy:/app/taxonomy lvmh-pipeline
```

---

## ğŸ“ˆ Performance

| MÃ©trique | Valeur |
|----------|--------|
| **Pipeline total** | ~65s (100 notes, 10 stages) |
| **Qwen Enhancement** | ~10s/note (99% success) |
| **Rule-based Detection** | <1ms/note |
| **Budget Extraction** | <1ms/note (100% coverage) |
| **Vocabulaire** | **575 concepts, 9,003 aliases** |
| **Concepts dÃ©tectÃ©s** | **1,796 total** (1,454 rule + 342 LLM) |
| **LLM Confidence** | 0.91 average |
| **Budget Range** | â‚¬1,500 - â‚¬40,000+ (avg â‚¬13,070) |
| **Segments clients** | 7 clusters (silhouette 0.0573) |
| **Tags per client** | 12 personalized (budget first) |
| **Big O Tests** | 11/11 passing (5.15s) |
| **Database** | 100 clients synced (Neon PostgreSQL) |

---

## ğŸ” Exemple de RÃ©sultat

### EntrÃ©e (Transcription FR)
```
Mme Rousseau, avocate d'affaires, cliente occasionnelle. Cherche cadeau 
anniversaire mari, mars prochain. Budget flexible autour de 5000â‚¬. 
Mari collectionne montres vintage, joue au golf...
```

### Sortie (Profil avec Tags PersonnalisÃ©s)
```yaml
Client: CA_001
Segment: "Budget Amount | Mariage | Europe Travel"
Cluster: 0 (13 clients similaires)

Tags PersonnalisÃ©s (12):
  1. budget 5000â‚¬           â† Budget dÃ©tectÃ© en premier
  2. anniversaire           â† Occasion
  3. cadeau                 â† Intent
  4. collectionne           â† Lifestyle
  5. golf                   â† Lifestyle/Preferences
  6. vintage                â† Preferences
  7. mari                   â† Context
  8. mars                   â† Timeframe
  9. flexible               â† Constraints
  10. avocate               â† Profession
  11. occasionnelle         â† Client Type
  12. montres               â† Product Interest

Concepts dÃ©tectÃ©s (total: 15):
  Rule-based (12):
    - anniversaire (OCCASION)
    - cadeau (INTENT)
    - budget (CONSTRAINTS) â†’ extracted: 5000â‚¬
    - collectionne (LIFESTYLE)
    - golf (PREFERENCES)
    - vintage (PREFERENCES)
    ...
  
  LLM-enhanced (3):
    - "luxury timepiece interest" (conf: 0.92)
    - "spring event planning" (conf: 0.88)
    - "professional woman gifting" (conf: 0.85)

Actions recommandÃ©es:
  1. Gift Occasion Follow-up (score: 0.95)
     Triggers: anniversaire, cadeau, mars
  2. VIP Watch Collection Preview (score: 0.92)
     Triggers: collectionne, montres, vintage, budget 5000â‚¬
  3. Anniversary Special (score: 0.90)
     Triggers: anniversaire, mari
  4. Golf Accessories Recommendation (score: 0.85)
     Triggers: golf, lifestyle, budget

ML Predictions:
  - Purchase Probability: 0.78 (High)
  - Churn Risk: 0.12 (Low)
  - Estimated CLV: â‚¬12,450
```

---

## ğŸ› ï¸ DÃ©pannage

### Le pipeline ne trouve pas le modÃ¨le
```bash
make setup-models-local
```

### Erreur de mÃ©moire avec UMAP
Le pipeline bascule automatiquement sur PCA si UMAP Ã©choue.

### Permissions sur macOS
```bash
chmod +x LVMH_Pipeline.command
```

### Le launcher ne s'ouvre pas (macOS)
```bash
xattr -d com.apple.quarantine LVMH_Pipeline.command
```

---

## ğŸ“š Documentation ComplÃ©mentaire

- [docs/prd.md](docs/prd.md) - Product Requirements Document
- [docs/agents.md](docs/agents.md) - Documentation des agents

---

## ğŸ“„ Licence

Proprietary - LVMH Â© 2026

---

<p align="center">
  <i>DÃ©veloppÃ© pour LVMH - Transformation des interactions clients en insights actionnables</i>
</p>
